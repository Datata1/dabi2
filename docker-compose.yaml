# docker-compose.yaml
version: '3.8' 

services:
  db:  # do we need some special extension?
    image: timescale/timescaledb:latest-pg16 
    container_name: dabi2-db
    environment:
      POSTGRES_USER: ${DB_USER:-datata1}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-devpassword}
      POSTGRES_DB: ${DB_NAME:-oltp}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init_scripts:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    restart: unless-stopped
    command: postgres -c wal_level=logical
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5

  prefect:
    container_name: prefect_server_dabi2
    image: prefecthq/prefect:3-latest 
    command: prefect server start --host 0.0.0.0
    environment:
      - PREFECT_SERVER_DATABASE_CONNECTION_URL=postgresql+asyncpg://${DB_USER}:${DB_PASSWORD}@db:${DB_PORT}/${PREFECT_DB_NAME}
      - PREFECT_API_URL=http://0.0.0.0:4200/api
      - PREFECT_UI_SERVE_BASE=/prefect
    depends_on:
      db:
        condition: service_healthy
      kafka-connect:
          condition: service_healthy
    restart: unless-stopped
    ports:
      - "4200:4200"

  prefect-worker:
    container_name: prefect_worker_dabi2
    build:
      context: ./src/prefect 
      dockerfile: Dockerfile
    develop:
      watch:
        - action: sync
          path: .
          target: /app
          ignore: 
            - .venv/
        - action: rebuild
          path: ./pyproject.toml 
    volumes:
      - ./data:/app/data
      - ./src/prefect/dbt_setup:/app/dbt_setup
    working_dir: /app
    command: "uv run run_worker.py"
    environment:
      - PREFECT_API_URL=http://prefect:4200/api
      - DATABASE_URL_PREFECT=postgresql+asyncpg://${DB_USER}:${DB_PASSWORD}@db:${DB_PORT}/${PREFECT_DB_NAME}
      - PREFECT_WORKER_WEBSERVER_PORT=8001
      - PG_DWH_HOST=db
      - PG_DWH_PORT=${DB_PORT:-5432}
      - PG_DWH_USER=${DB_USER:-datata1}
      - PG_DWH_PASSWORD=${DB_PASSWORD:-devpassword}
      - PG_DWH_DBNAME=${DB_NAME:-dwh_dabi}
      - DBT_PROJECT_DIR=/app/dbt_setup
      - DBT_PROFILES_DIR=/app/dbt_setup
      - MINIO_ROOT_PASSWORD=minio_secret_password
      - MINIO_ROOT_USER=minioadmin
    depends_on:
      prefect:
        condition: service_started
      kafka-connect:
          condition: service_healthy
    restart: unless-stopped
    ports:
      - "8001:8001"
  
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.2 # Beispielversion, prüfe Kompatibilität
    container_name: zookeeper_dabi2
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
        test: ["CMD", "echo", "ruok", "|", "nc", "localhost", "2181"]
        interval: 10s
        timeout: 5s
        retries: 5
  
  kafka:
    image: confluentinc/cp-kafka:7.3.2 # Beispielversion
    container_name: kafka_dabi2
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    healthcheck:
        test: ["CMD", "echo", "exit", "|", "nc", "localhost", "29092"]
        interval: 10s
        timeout: 5s
        retries: 5
  
  kafka-connect:
    image: debezium/connect:2.1 #
    container_name: kafka_connect_dabi2
    depends_on:
      kafka:
        condition: service_healthy
      db: 
          condition: service_healthy
    ports:
      - "8083:8083"
    environment:
      BOOTSTRAP_SERVERS: 'kafka:29092' # Interner Kafka-Port
      GROUP_ID: dabi2_connect_cluster
      CONFIG_STORAGE_TOPIC: dabi2_connect_configs
      OFFSET_STORAGE_TOPIC: dabi2_connect_offsets
      STATUS_STORAGE_TOPIC: dabi2_connect_status
      KAFKA_HEAP_OPTS: "-Xmx4g -Xms1g"
      # Umgebungsvariablen für die OLTP DB Verbindung (für Debezium)
      # Debezium verwendet diese oft, um nicht alles im Connector-JSON zu haben
      CONNECT_DATABASE_HOSTNAME: ${DB_HOST:-oltp-db}
      CONNECT_DATABASE_PORT: ${DB_PORT:-5432}
      CONNECT_DATABASE_USER: ${DB_USER:-oltp_user} # User mit Replication-Rechten!
      CONNECT_DATABASE_PASSWORD: ${DB_PASSWORD}
      CONNECT_DATABASE_DBNAME: ${DB_NAME:-oltp}
    healthcheck:
        test: ["CMD", "curl", "-f", "http://localhost:8083/connectors"]
        interval: 10s
        timeout: 5s
        retries: 5

  
  akhq:
    image: tchiotludo/akhq:latest 
    container_name: akhq_ui_dabi2
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            docker-kafka-cluster:
              properties:
                bootstrap.servers: "kafka:29092"
              connect: 
                - name: "connect-cluster-1" # Name für den Connect Cluster in AKHQ
                  url: "http://kafka-connect:8083" 
    
    ports:
      - "8080:8080" 
    depends_on:
      kafka:
        condition: service_healthy
      kafka-connect:
        condition: service_healthy

  jupyter-lab:
    build:
      context: ./notebooks 
      dockerfile: Dockerfile 
    develop:
      watch:
        - action: sync
          path: .
          target: /app
          ignore: 
            - .venv/
        - action: rebuild
          path: ./pyproject.toml
    container_name: jupyter_lab_dabi2
    volumes:
      - ./notebooks:/app/
      - jupyter_config:/root/.jupyter           
      - jupyter_data:/root/.local/share/jupyter 
      - jupyter_cache:/root/.cache 
    ports:
      - "8888:8888" 
    working_dir: /app
    environment: 
      - OLTP_DB_HOST=db
      - OLTP_DB_PORT=5432
      - OLTP_DB_USER=${DB_USER:-datata1}
      - OLTP_DB_PASSWORD=${DB_PASSWORD:-devpassword}
      - OLTP_DB_NAME=${DB_NAME:-oltp}
      - PREFECT_API_URL=http://prefect:4200/api
      - DUCK_DWH_PATH=/app/data/dev.duckdb
    restart: unless-stopped
    depends_on:
      db: 
        condition: service_healthy
      prefect: 
        condition: service_started
    command: > 
      uv run jupyter lab
      --ServerApp.base_url=/jupyter
      --ServerApp.token='dabi2'
      --ServerApp.ip='0.0.0.0'
      --ServerApp.port=8888
      --no-browser
      --allow-root 
      --NotebookApp.notebook_dir=/app/notebooks
  
  minio:
    image: minio/minio:latest
    container_name: minio_dabi2
    ports:
      # Port 9000 für die API, Port 9001 für die Web UI
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data # Persistenter Speicher für MinIO Buckets/Objekte
    environment:
      # Setze deine Zugangsdaten - ÄNDERN!
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minio_secret_password # ÄNDERN!
    command: server /data --console-address ":9001" # Startet Server und Konsole
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5
    
  cdc-lake-writer:
    build:
      context: ./src/consumers 
      dockerfile: Dockerfile
    develop:
      watch:
        - action: sync
          path: .
          target: /app
          ignore: 
            - .venv/
        - action: rebuild
          path: ./pyproject.toml
    container_name: cdc_lake_writer_dabi2
    depends_on:
      kafka:
        condition: service_healthy
      minio:
        condition: service_healthy 
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - MINIO_ENDPOINT=${MINIO_ENDPOINT}
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
      - MINIO_BUCKET=${MINIO_BUCKET}
      - KAFKA_TOPIC_PATTERN=${KAFKA_TOPIC_PATTERN} 
      - CONSUMER_GROUP_ID=${CONSUMER_GROUP_ID} 
      - PREFECT_API_URL=http://prefect:4200/api
    restart: unless-stopped

  caddy:
    container_name: caddy_proxy_dabi2
    image: caddy:latest
    restart: unless-stopped
    ports:
      - "3000:3000"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - caddy_data:/data
      - caddy_config:/config
    depends_on:
      - prefect
      - jupyter-lab 
      - minio

# --- Benannte Volumes für persistente Daten ---
volumes:
  postgres_data:
  caddy_data:
  minio_data:
  caddy_config:
  jupyter_config:
  jupyter_data:
  jupyter_cache: